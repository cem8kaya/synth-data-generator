## ğŸ“Š TELECOM SYNTHETIC DATA GENERATOR 

### ğŸ¯ **UYGULAMA AMACI**

Bu uygulama, **telekom operatÃ¶rleri iÃ§in gerÃ§ekÃ§i sentetik network KPI verisi Ã¼reten** profesyonel bir sistemdir. AsÄ±l amacÄ±:
- Machine learning modellerinin eÄŸitimi
- Kapasite planlamasÄ± simÃ¼lasyonu  
- Anomali tespit algoritmalarÄ±nÄ±n geliÅŸtirilmesi
- Hassas operasyonel verilerin paylaÅŸÄ±lmadan test ortamlarÄ± oluÅŸturulmasÄ±

---

### ğŸ—ï¸ **MÄ°MARÄ° TASARIM - 6 KATMANLI MODEL**

Uygulama, **modÃ¼ler katmanlÄ± mimari** kullanarak Ã§alÄ±ÅŸÄ±r:

```
LAYER 6: Validation & Quality Assurance
           â†“ (validates)
LAYER 5: Anomaly Modeling & Scenarios
           â†“ (injects anomalies)
LAYER 4: Procedure Simulation
           â†“ (simulates protocols)
LAYER 3: Temporal Engineering & Time Series
           â†“ (applies seasonality, ARIMA)
LAYER 2: Multivariate Dependency Modeling
           â†“ (applies correlations, dependencies)
LAYER 1: Statistical Foundation
           â†“ (generates base distributions)
Raw Random Numbers
```

---

### ğŸ”¬ **KULLANILAN METODLAR VE MODELLER**

#### **1. Ä°statistiksel DaÄŸÄ±lÄ±mlar (Layer 1)**

| DaÄŸÄ±lÄ±m | KullanÄ±m AlanÄ± | Parametreler |
|---------|---------------|--------------|
| **Poisson** | Event arrival rates, Ã§aÄŸrÄ± denemeleri | Î» (mean) |
| **Gamma** | Latency, gecikme, iÅŸleme sÃ¼releri | shape (Î±), scale (Î¸), CV |
| **Log-Normal** | Throughput, bandwidth, data volume | Î¼, Ïƒ (log-scale) |
| **Beta** | Success rates, availability (0-1 arasÄ±) | Î±, Î², stability level |
| **Exponential** | Inter-arrival times, failure times | rate (Î») |
| **Normal** | Genel metrikler | mean (Î¼), std (Ïƒ) |

**Parametre Hesaplama Ã–rnekleri:**
```python
# Gamma iÃ§in shape ve scale hesaplama
cv = std / mean  # Coefficient of Variation
shape = 1 / (cv ** 2)
scale = mean / shape

# Beta iÃ§in alpha ve beta hesaplama
concentration = {HIGH: 50, MEDIUM: 10, LOW: 2}[stability]
alpha = target_rate * concentration
beta = (1 - target_rate) * concentration
```

#### **2. Ã‡ok DeÄŸiÅŸkenli BaÄŸÄ±mlÄ±lÄ±k Modelleri (Layer 2)**

- **Gaussian Copula**: FarklÄ± daÄŸÄ±lÄ±mlara sahip metrikler arasÄ± korelasyon
  - Uniform deÄŸerleri standart normale transform eder (CDF â†’ Normal PPF)
  - Korelasyon matrisini Cholesky decomposition ile uygular
  - Geri original daÄŸÄ±lÄ±ma inverse transform eder

- **Bayesian Network**: Nedensel iliÅŸkiler (Ã¶rn: latency â†‘ â†’ success rate â†“)

- **Conditional Probability Chain**: ProsedÃ¼r state machine'leri
  - SIP call flows
  - PDU session establishment
  - NAS procedures

#### **3. Zaman Serisi MÃ¼hendisliÄŸi (Layer 3)**

**Fourier Series ile Seasonality:**
```python
seasonal = Î£ (amplitude/h) * sin(2Ï€h*f*t + Ï†)
# h: harmonic order (1-10)
# f: base frequency (24h, 7d, 30d)
```

**ARIMA Modeli (AutoRegressive Integrated Moving Average):**
- **AR(p)**: GeÃ§miÅŸ deÄŸerlere baÄŸlÄ± (temporal smoothing)
- **MA(q)**: GeÃ§miÅŸ hatalara baÄŸlÄ± (noise cancellation)

```python
value[t] = 0.3*base[t] + 0.5*AR_component + 0.2*MA_component + noise[t]
AR_component = Î£ ar_coef[i] * value[t-i-1]
MA_component = Î£ ma_coef[i] * noise[t-i-1]
```

**Change Point Detection:**
- **STEP**: AnlÄ±k deÄŸiÅŸim (software upgrade)
- **RAMP**: AÅŸamalÄ± deÄŸiÅŸim (capacity expansion)
- **SPIKE**: GeÃ§ici deÄŸiÅŸim (special event)

#### **4. Anomali Modelleme (Layer 5)**

| Anomali Tipi | Etki | Propagation |
|--------------|------|-------------|
| **SPIKE** | Ani artÄ±ÅŸ | value *= (1 + severity) |
| **DROP** | Ani dÃ¼ÅŸÃ¼ÅŸ | value *= (1 - severity) |
| **OSCILLATION** | SalÄ±nÄ±m | sin-wave pattern |
| **CONGESTION** | Network tÄ±kanÄ±klÄ±ÄŸÄ± | successâ†“, latencyâ†‘ |
| **DEGRADATION** | Kademeli bozulma | Zaman iÃ§inde artÄ±ÅŸ |
| **OUTAGE** | Tam kesinti | value *= (1 - 0.8*severity) |

---

### âš™ï¸ **CONFIGURATION YAPISI**

#### **Ana KonfigÃ¼rasyon BileÅŸenleri:**

```python
GeneratorConfig:
  â”œâ”€ seed: int                    # Reproducibility iÃ§in
  â”œâ”€ start_time / end_time: str   # Zaman penceresi
  â”œâ”€ granularity_minutes: int     # Ã–rnekleme aralÄ±ÄŸÄ± (5, 15, 30 dk)
  â”œâ”€ nodes: List[NodeConfig]      # Network node'larÄ±
  â”œâ”€ seasonality: SeasonalityConfig
  â”œâ”€ arima: ARIMAConfig
  â”œâ”€ correlations: List[CorrelationConfig]
  â”œâ”€ change_points: List[ChangePointConfig]
  â”œâ”€ anomalies: List[AnomalyConfig]
  â””â”€ validation: ValidationConfig
```

#### **Node ve Metric KonfigÃ¼rasyonu:**

```python
NodeConfig:
  â”œâ”€ node_id: str          # Unique identifier
  â”œâ”€ node_type: str        # IMS, 4G, 5G Core
  â”œâ”€ capacity: int         # Max users/sessions
  â”œâ”€ location: str
  â””â”€ metrics: List[MetricConfig]
      â”œâ”€ name: str
      â”œâ”€ distribution: DistributionConfig
      â”œâ”€ dependencies: List[str]    # BaÄŸÄ±mlÄ± metrikler
      â”œâ”€ qos_min / qos_max: float  # QoS boundaries
```

#### **Korelasyon TanÄ±mlama:**

```python
CorrelationConfig:
  â”œâ”€ source: str            # Kaynak metrik
  â”œâ”€ target: str            # Hedef metrik
  â””â”€ coefficient: float     # -1 to +1 arasÄ±
  
# Ã–rnek: latency â†‘ â†’ success_rate â†“
correlation = CorrelationConfig(
    source="latency",
    target="success_rate",
    coefficient=-0.7
)
```

---

### ğŸ”„ **Ã‡ALIÅMA AKIÅI (TEXT-BASED FLOW)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. BAÅLANGIÃ‡ - CONFIGURATION PARSING                        â”‚
â”‚    User Input (JSON/YAML) â†’ parse_config()                  â”‚
â”‚    â””â”€> GeneratorConfig object oluÅŸturulur                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TIME WINDOW GENERATION                                   â”‚
â”‚    pd.date_range(start_time, end_time, freq=granularity)    â”‚
â”‚    â””â”€> Zaman damgalarÄ± listesi oluÅŸturulur                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LAYER 1 - BASE DISTRIBUTION GENERATION                   â”‚
â”‚    For each node and metric:                                â”‚
â”‚      â”œâ”€> Select distribution type (Poisson, Gamma, etc.)    â”‚
â”‚      â”œâ”€> Calculate parameters (shape, scale, Î±, Î²)          â”‚
â”‚      â””â”€> Generate random values: np.random.{dist}()         â”‚
â”‚    Result: raw_values[n_windows]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LAYER 3 - TEMPORAL PATTERNS APPLICATION                  â”‚
â”‚    A) Seasonality (Fourier Series):                         â”‚
â”‚       â””â”€> Apply daily/weekly cycles                         â”‚
â”‚           values *= (1 + Î£ sin(harmonics))                  â”‚
â”‚                                                              â”‚
â”‚    B) ARIMA Smoothing:                                      â”‚
â”‚       â””â”€> Apply AR and MA components                        â”‚
â”‚           value[t] = f(value[t-1..t-p], noise[t-1..t-q])   â”‚
â”‚                                                              â”‚
â”‚    Result: temporal_values[n_windows]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CHANGE POINTS APPLICATION                                â”‚
â”‚    For each change_point in config:                         â”‚
â”‚      â”œâ”€> Find timestamp index in time_windows               â”‚
â”‚      â”œâ”€> Apply change based on type:                        â”‚
â”‚      â”‚    â€¢ STEP: instant *= (1 + magnitude)               â”‚
â”‚      â”‚    â€¢ RAMP: gradual over duration                     â”‚
â”‚      â”‚    â€¢ SPIKE: Gaussian bump                            â”‚
â”‚      â””â”€> Update values[idx:end]                             â”‚
â”‚    Result: changed_values[n_windows]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. LAYER 5 - ANOMALY INJECTION                             â”‚
â”‚    For each anomaly in config:                              â”‚
â”‚      â”œâ”€> Find start/end indices                             â”‚
â”‚      â”œâ”€> Apply anomaly effect based on type:                â”‚
â”‚      â”‚    â€¢ SPIKE: values *= (1 + severity)                 â”‚
â”‚      â”‚    â€¢ CONGESTION: if 'latency' *= 2, 'success' /= 2  â”‚
â”‚      â”‚    â€¢ OUTAGE: values *= (1 - 0.8*severity)           â”‚
â”‚      â””â”€> Propagate if enabled (via dependency graph)        â”‚
â”‚    Result: anomalous_values[n_windows]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. LAYER 2 - DEPENDENCIES & CORRELATIONS                   â”‚
â”‚    A) Apply Dependencies:                                    â”‚
â”‚       â””â”€> If metric depends on others:                      â”‚
â”‚           value *= scale_factor(dependency_values)           â”‚
â”‚                                                              â”‚
â”‚    B) Apply Correlations (Gaussian Copula):                 â”‚
â”‚       â””â”€> Normalize â†’ Apply correlation matrix              â”‚
â”‚           â†’ Transform back                                   â”‚
â”‚                                                              â”‚
â”‚    Result: correlated_values[n_windows]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. QoS ENFORCEMENT                                          â”‚
â”‚    For each metric with qos_min/max:                        â”‚
â”‚      â”œâ”€> np.maximum(values, qos_min)                        â”‚
â”‚      â””â”€> np.minimum(values, qos_max)                        â”‚
â”‚    Result: bounded_values[n_windows]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. DATAFRAME CONSTRUCTION                                   â”‚
â”‚    df = pd.DataFrame({                                       â”‚
â”‚        'timestamp': time_windows,                            â”‚
â”‚        'node1_metric1': values1,                            â”‚
â”‚        'node1_metric2': values2,                            â”‚
â”‚        ...                                                   â”‚
â”‚    })                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. LAYER 6 - VALIDATION                                    â”‚
â”‚     Statistical Validation:                                  â”‚
â”‚       â”œâ”€> Check for NaN/Inf values                          â”‚
â”‚       â”œâ”€> Verify distribution moments match                 â”‚
â”‚       â””â”€> KS test for distribution fit                      â”‚
â”‚                                                              â”‚
â”‚     Logical Validation:                                      â”‚
â”‚       â”œâ”€> QoS boundary compliance                           â”‚
â”‚       â””â”€> Metric ordering (e.g., p50 < p95)                â”‚
â”‚                                                              â”‚
â”‚     Temporal Validation:                                     â”‚
â”‚       â”œâ”€> Autocorrelation structure                         â”‚
â”‚       â”œâ”€> Seasonality detection                             â”‚
â”‚       â””â”€> Change point detection                            â”‚
â”‚                                                              â”‚
â”‚     Quality Score = Î£ (weight_i * score_i)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 11. OUTPUT GENERATION                                        â”‚
â”‚     Formats:                                                 â”‚
â”‚       â€¢ CSV  â†’ df.to_csv()                                  â”‚
â”‚       â€¢ JSON â†’ df.to_json(orient='records')                 â”‚
â”‚       â€¢ Parquet â†’ df.to_parquet()                           â”‚
â”‚       â€¢ SAR Format â†’ export_sar_format() (custom)           â”‚
â”‚                                                              â”‚
â”‚     Metadata:                                                â”‚
â”‚       â€¢ Generation time                                      â”‚
â”‚       â€¢ Quality score                                        â”‚
â”‚       â€¢ Configuration summary                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    [COMPLETED]
```

---

### ğŸŒ **API ENDPOINTS**

#### **1. POST /api/generate**
- **AmaÃ§**: Sentetik data Ã¼retimi
- **Input**: JSON configuration (nodes, metrics, anomalies, etc.)
- **Process**: YukarÄ±daki flow'u Ã§alÄ±ÅŸtÄ±rÄ±r
- **Output**: Generated DataFrame + metadata

#### **2. GET /api/download**
- **AmaÃ§**: Ãœretilen veriyi indir
- **Params**: format (csv/json/parquet/sar)
- **Output**: File download

#### **3. GET /api/health**
- **AmaÃ§**: Servis saÄŸlÄ±k kontrolÃ¼
- **Output**: {"status": "healthy", "version": "2.1"}

---

### ğŸ”§ **TEMEL SINIFLAR VE DATA YAPILARI**

```python
# Core Classes
DataGenerator(config: GeneratorConfig)
  â””â”€ generate() â†’ pd.DataFrame

# Configuration Classes
GeneratorConfig      # Ana konfigÃ¼rasyon
NodeConfig          # Node tanÄ±mlarÄ±
MetricConfig        # Metrik tanÄ±mlarÄ±
DistributionConfig  # DaÄŸÄ±lÄ±m parametreleri
SeasonalityConfig   # Mevsimsellik ayarlarÄ±
ARIMAConfig         # ARIMA parametreleri
CorrelationConfig   # Korelasyon tanÄ±mlarÄ±
ChangePointConfig   # DeÄŸiÅŸim noktalarÄ±
AnomalyConfig       # Anomali senaryolarÄ±
ValidationConfig    # DoÄŸrulama kriterleri

# Enums
DistributionType    # normal, gamma, beta, etc.
AnomalyType        # spike, drop, congestion, etc.
ChangeType         # step, ramp
StabilityLevel     # high, medium, low
```

---

### ğŸ“ˆ **Ã–ZELLEÅME VE GENÄ°ÅLETME NOKTALARI**

1. **Yeni DaÄŸÄ±lÄ±m Ekleme**: `_generate_base_distribution()` metoduna yeni case
2. **Yeni Anomali Tipi**: `_apply_anomalies()` metoduna yeni elif bloÄŸu
3. **Custom Korelasyon**: `_apply_correlations()` metodunda Gaussian Copula yerine baÅŸka yÃ¶ntem
4. **ProsedÃ¼r Simulasyonu**: Layer 4'e state machine ekleyerek
5. **Yeni Validasyon**: `calculate_validation_score()` fonksiyonuna yeni metrik

---